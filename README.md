#LexGenius: An Expert-Level Benchmark for Large Language Models in Chinese Legal General Intelligence

<div align="center">

[![arXiv](https://img.shields.io/badge/arXiv-Coming%20Soon-b31b1b.svg)](#)
[![GitHub](https://img.shields.io/badge/GitHub-LexGenius-black.svg)](https://github.com/QwenQKing/LexGenius)
[![Dataset](https://img.shields.io/badge/Dataset-HuggingFace-orange.svg)](https://huggingface.co/datasets/QwenQKing/LexGenius)
[![HF Models](https://img.shields.io/badge/HF%20Models-HuggingFace-yellow.svg)](https://huggingface.co/QwenQKing/LexGenius)

### **LexGenius**: An Expert-Level Benchmark for Large Language Models in Chinese Legal General Intelligence

[ðŸ“„ Paper](https://arxiv.org/abs/2511.01016) | [ðŸš€ Quick Start](#quick-start-prompt-r1) | [ðŸ’¬ Contact](mailto:wenjinliu23@outlook.com)

</div>

---

## Overview

Chinese LegalBench
Chinese LegalBench is a comprehensive expert-level benchmark designed to evaluate the legal general intelligence (GI) of large language models (LLMs) in the Chinese legal domain. It introduces a structured and interpretable evaluation framework that assesses LLMs across 7 legal dimensions, 11 tasks, and 20 atomic legal abilities, covering both hard and soft aspects of legal cognition.# CNLegalBench
